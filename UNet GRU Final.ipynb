{"cells": [{"cell_type": "markdown", "metadata": {"id": "7B9CtxAwlp20"}, "source": ["<center>\n", "    <h1>Cloud Movement Diffusion</h1>\n", "    <h2>Artificial Intelligence in Industry</h2>\n", "    <h3>Facundo Nicolas Maidana, Farshid Mahmoudabadi, and Riccardo Spolaor</h3>\n", "    <h4>riccardo.spolaor@studio.unibo.it</h4>\n", "</center>\n", "\n", "---\n", "\n", "This project explores the use of diffusion models for short-term solar energy forecasting. Diffusion models are a type of generative model that can be used to predict the future state of a system by gradually \"diffusing\" from the current state. In this project, we train a diffusion model on a dataset of cloud images. We then use the model to predict the future state of the clouds, which can be used to forecast solar energy production.\n", "\n", "Introduction:\n", "\n", "Solar energy is a promising renewable energy source, but it is intermittent. This means that the amount of solar energy produced can vary significantly from day to day. Short-term solar energy forecasting can help to mitigate this variability by providing estimates of solar energy production in the near future.\n", "\n", "Diffusion models:\n", "\n", "Diffusion models are a type of generative model that can be used to predict the future state of a system by gradually \"diffusing\" from the current state. Diffusion models are trained on a dataset of images, and they can be used to generate new images that are similar to the images in the dataset.\n", "\n", "Project goals:\n", "\n", "The goals of this project are to:\n", "\n", "Train a diffusion model on a dataset of cloud images.\n", "Use the model to predict the future state of the clouds.\n", "Use the predicted cloud state to forecast solar energy production.\n", "\n", "Project results:\n", "\n", "The results of this project show that diffusion models can be used to predict the future state of the clouds with some accuracy. The predicted cloud state can then be used to forecast solar energy production."]}, {"cell_type": "markdown", "metadata": {"id": "NwQLlqhclp29"}, "source": ["# Settings"]}, {"cell_type": "code", "execution_count": 1, "metadata": {"id": "oWV0TU0vlp2_", "executionInfo": {"status": "ok", "timestamp": 1696937432234, "user_tz": -120, "elapsed": 748, "user": {"displayName": "Riccardo Spolaor", "userId": "04097970246471970760"}}}, "outputs": [], "source": ["# Settings for autoreloading.\n", "\n", "%load_ext autoreload\n", "%autoreload 2"]}, {"cell_type": "code", "execution_count": 2, "metadata": {"id": "viaAGE5Wlp3E", "executionInfo": {"status": "ok", "timestamp": 1696937437725, "user_tz": -120, "elapsed": 4828, "user": {"displayName": "Riccardo Spolaor", "userId": "04097970246471970760"}}}, "outputs": [], "source": ["!pip install -q wandb tqdm matplotlib diffusers fastcore fastprogress torchmetrics"]}, {"cell_type": "code", "source": ["from types import SimpleNamespace\n", "\n", "# TODO: Some of these parameters are not used, remove them.\n", "config = SimpleNamespace(\n", "    epochs=101, # Number of epochs.\n", "    model_name='unet_small', # Model name to save [unet_small, unet_big].\n", "    strategy='ddpm', # Strategy to use ddpm.\n", "    noise_steps=1_000, # Number of noise steps on the diffusion process.\n", "    sampler_steps=333, # Number of sampler steps on the diffusion process.\n", "    seed=42, # Random seed.\n", "    batch_size=128, # Batch size.\n", "    img_size=64, # Image size.\n", "    device='cuda', # Device to use.\n", "    num_workers=0, # Number of workers for dataloader.\n", "    num_input_frames=3, # Number of frames to use as input for the training.\n", "    lr=5e-4, # Learning rate.\n", "    log_every_epoch=5, # Log every n epochs to wandb.\n", "    num_prediction_frames=1, # Number of predictions to make.\n", "    num_channels=1, # Number of channels.\n", "    validate_epochs=False, # Whether to validate every epoch.\n", "    )"], "metadata": {"id": "NPBkBvLGBZtP", "executionInfo": {"status": "ok", "timestamp": 1696937437725, "user_tz": -120, "elapsed": 12, "user": {"displayName": "Riccardo Spolaor", "userId": "04097970246471970760"}}}, "execution_count": 3, "outputs": []}, {"cell_type": "code", "execution_count": 4, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "DmDy1gou52FF", "outputId": "a58bfb04-1cb2-4f5d-bacd-26400c23120d", "executionInfo": {"status": "ok", "timestamp": 1696937441729, "user_tz": -120, "elapsed": 4013, "user": {"displayName": "Riccardo Spolaor", "userId": "04097970246471970760"}}}, "outputs": [{"output_type": "stream", "name": "stderr", "text": ["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mriccardo-spolaor94\u001b[0m (\u001b[33mai-industry\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n", "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n", "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n", "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]}, {"output_type": "execute_result", "data": {"text/plain": ["True"]}, "metadata": {}, "execution_count": 4}], "source": ["import wandb\n", "wandb.login(key='d3d31786e16c5dffe9ee01690d0bb069cac55e84')"]}, {"cell_type": "markdown", "metadata": {"id": "PKsut0uVlp3p"}, "source": ["## training"]}, {"cell_type": "code", "execution_count": 5, "metadata": {"id": "O-b2ZMyalp3q", "executionInfo": {"status": "ok", "timestamp": 1696937441732, "user_tz": -120, "elapsed": 24, "user": {"displayName": "Riccardo Spolaor", "userId": "04097970246471970760"}}}, "outputs": [], "source": ["PROJECT_NAME = 'sevir'\n", "DATASET_ARTIFACT = 'ai-industry/sevir/SEVIR:latest'\n", "SCALERS_ARTIFACT = 'ai-industry/sevir/scalers:latest'"]}, {"cell_type": "code", "execution_count": 6, "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 35}, "id": "sE1UK18GngHy", "outputId": "374948bc-07bf-4ad6-e90c-9be77feead3d", "executionInfo": {"status": "ok", "timestamp": 1696937441733, "user_tz": -120, "elapsed": 23, "user": {"displayName": "Riccardo Spolaor", "userId": "04097970246471970760"}}}, "outputs": [{"output_type": "execute_result", "data": {"text/plain": ["'ai-industry/sevir/SEVIR:latest'"], "application/vnd.google.colaboratory.intrinsic+json": {"type": "string"}}, "metadata": {}, "execution_count": 6}], "source": ["DATASET_ARTIFACT"]}, {"cell_type": "code", "execution_count": 7, "metadata": {"id": "1RfynEhyn9ni", "executionInfo": {"status": "ok", "timestamp": 1696937441734, "user_tz": -120, "elapsed": 20, "user": {"displayName": "Riccardo Spolaor", "userId": "04097970246471970760"}}}, "outputs": [], "source": ["# TODO: repeated code just do the scaling here.\n", "import numpy as np\n", "\n", "class Scaler():\n", "    def __init__(self, dataset: np.ndarray) -> None:\n", "        self.min = dataset.min()\n", "        self.max = dataset.max()\n", "\n", "    def scale(self, array: np.ndarray) -> np.ndarray:\n", "        return .5 - (array - self.min) / (self.max - self.min)\n", "\n", "    def unscale(self, array: np.ndarray) -> np.ndarray:\n", "        return ((.5 - array) * (self.max - self.min)) + self.min"]}, {"cell_type": "code", "execution_count": 8, "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 468}, "id": "qHVis0UQHLk2", "outputId": "251072be-1251-4055-b7cc-7f56efd87693", "executionInfo": {"status": "ok", "timestamp": 1696937482782, "user_tz": -120, "elapsed": 41067, "user": {"displayName": "Riccardo Spolaor", "userId": "04097970246471970760"}}}, "outputs": [{"output_type": "display_data", "data": {"text/plain": ["<IPython.core.display.HTML object>"], "text/html": ["Tracking run with wandb version 0.15.12"]}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["<IPython.core.display.HTML object>"], "text/html": ["Run data is saved locally in <code>/content/wandb/run-20231010_113043-qijey5fg</code>"]}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["<IPython.core.display.HTML object>"], "text/html": ["Syncing run <strong><a href='https://wandb.ai/ai-industry/sevir/runs/qijey5fg' target=\"_blank\">good-music-120</a></strong> to <a href='https://wandb.ai/ai-industry/sevir' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"]}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["<IPython.core.display.HTML object>"], "text/html": [" View project at <a href='https://wandb.ai/ai-industry/sevir' target=\"_blank\">https://wandb.ai/ai-industry/sevir</a>"]}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["<IPython.core.display.HTML object>"], "text/html": [" View run at <a href='https://wandb.ai/ai-industry/sevir/runs/qijey5fg' target=\"_blank\">https://wandb.ai/ai-industry/sevir/runs/qijey5fg</a>"]}, "metadata": {}}, {"output_type": "stream", "name": "stderr", "text": ["\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact SEVIR:latest, 8544.38MB. 9 files... \n", "\u001b[34m\u001b[1mwandb\u001b[0m:   9 of 9 files downloaded.  \n", "Done. 0:0:5.8\n"]}, {"output_type": "display_data", "data": {"text/plain": ["<IPython.core.display.HTML object>"], "text/html": ["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["<IPython.core.display.HTML object>"], "text/html": [" View run <strong style=\"color:#cdcd00\">good-music-120</strong> at: <a href='https://wandb.ai/ai-industry/sevir/runs/qijey5fg' target=\"_blank\">https://wandb.ai/ai-industry/sevir/runs/qijey5fg</a><br/> View job at <a href='https://wandb.ai/ai-industry/sevir/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEwMDI0Nzg1Nw==/version_details/v26' target=\"_blank\">https://wandb.ai/ai-industry/sevir/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEwMDI0Nzg1Nw==/version_details/v26</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)"]}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["<IPython.core.display.HTML object>"], "text/html": ["Find logs at: <code>./wandb/run-20231010_113043-qijey5fg/logs</code>"]}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["<IPython.core.display.HTML object>"], "text/html": ["Tracking run with wandb version 0.15.12"]}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["<IPython.core.display.HTML object>"], "text/html": ["Run data is saved locally in <code>/content/wandb/run-20231010_113106-6doj9d8v</code>"]}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["<IPython.core.display.HTML object>"], "text/html": ["Syncing run <strong><a href='https://wandb.ai/ai-industry/sevir/runs/6doj9d8v' target=\"_blank\">major-tree-121</a></strong> to <a href='https://wandb.ai/ai-industry/sevir' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"]}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["<IPython.core.display.HTML object>"], "text/html": [" View project at <a href='https://wandb.ai/ai-industry/sevir' target=\"_blank\">https://wandb.ai/ai-industry/sevir</a>"]}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["<IPython.core.display.HTML object>"], "text/html": [" View run at <a href='https://wandb.ai/ai-industry/sevir/runs/6doj9d8v' target=\"_blank\">https://wandb.ai/ai-industry/sevir/runs/6doj9d8v</a>"]}, "metadata": {}}, {"output_type": "stream", "name": "stderr", "text": ["\u001b[34m\u001b[1mwandb\u001b[0m: \\ 1 of 3 files downloaded...\r\u001b[34m\u001b[1mwandb\u001b[0m:   3 of 3 files downloaded.  \n"]}, {"output_type": "display_data", "data": {"text/plain": ["<IPython.core.display.HTML object>"], "text/html": ["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["<IPython.core.display.HTML object>"], "text/html": [" View run <strong style=\"color:#cdcd00\">major-tree-121</strong> at: <a href='https://wandb.ai/ai-industry/sevir/runs/6doj9d8v' target=\"_blank\">https://wandb.ai/ai-industry/sevir/runs/6doj9d8v</a><br/> View job at <a href='https://wandb.ai/ai-industry/sevir/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEwMDI0Nzg1Nw==/version_details/v27' target=\"_blank\">https://wandb.ai/ai-industry/sevir/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEwMDI0Nzg1Nw==/version_details/v27</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)"]}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["<IPython.core.display.HTML object>"], "text/html": ["Find logs at: <code>./wandb/run-20231010_113106-6doj9d8v/logs</code>"]}, "metadata": {}}], "source": ["import torch\n", "\n", "from src.seeder import set_seed\n", "from src.model import get_unet_params, add_gru_params\n", "from src.dataset_builder import download_dataset, download_scalers\n", "\n", "# Set the model parameters in the config file.\n", "'''config.model_params = get_unet_params(\n", "    model_name=config.model_name,\n", "    num_frames=10)''';\n", "\n", "# Set the model parameters in the config file.\n", "# TODO: base num_frames on config\n", "config.model_params = get_unet_params(\n", "    model_name=config.model_name,\n", "    num_input_frames=config.num_input_frames + config.num_prediction_frames,\n", "    num_output_frames=config.num_prediction_frames,\n", "    num_channels=config.num_channels)\n", "\n", "config.model_params = add_gru_params(\n", "    config.model_params,\n", "    num_input_past_frames=config.num_input_frames,\n", "    num_input_prediction_frames=config.num_prediction_frames,\n", "    num_channels=config.num_channels,\n", "    mode='last_output')\n", "\n", "# Set the seed and device.\n", "set_seed(config.seed)\n", "device = torch.device(config.device)\n", "\n", "# Downlaod the dataset from the wandb Artifact.\n", "files = download_dataset(DATASET_ARTIFACT, PROJECT_NAME)\n", "scalers = download_scalers(SCALERS_ARTIFACT, PROJECT_NAME)"]}, {"cell_type": "code", "execution_count": 9, "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 17}, "id": "HJSJ9D1oZ42p", "outputId": "0f98e70b-25ff-4e2c-c1ed-1396763bf9fe", "executionInfo": {"status": "ok", "timestamp": 1696937485585, "user_tz": -120, "elapsed": 2815, "user": {"displayName": "Riccardo Spolaor", "userId": "04097970246471970760"}}}, "outputs": [{"output_type": "display_data", "data": {"text/plain": ["<IPython.core.display.HTML object>"], "text/html": ["\n", "<style>\n", "    /* Turns off some styling */\n", "    progress {\n", "        /* gets rid of default border in Firefox and Opera. */\n", "        border: none;\n", "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n", "        background-size: auto;\n", "    }\n", "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n", "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n", "    }\n", "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n", "        background: #F44336;\n", "    }\n", "</style>\n"]}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["<IPython.core.display.HTML object>"], "text/html": []}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["<IPython.core.display.HTML object>"], "text/html": ["\n", "<style>\n", "    /* Turns off some styling */\n", "    progress {\n", "        /* gets rid of default border in Firefox and Opera. */\n", "        border: none;\n", "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n", "        background-size: auto;\n", "    }\n", "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n", "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n", "    }\n", "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n", "        background: #F44336;\n", "    }\n", "</style>\n"]}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["<IPython.core.display.HTML object>"], "text/html": []}, "metadata": {}}], "source": ["from src.dataset_builder import CloudDataset\n", "\n", "# Build the train and validation datasets.\n", "train_ds = CloudDataset(\n", "    files=files[1:2], # Use just ir069 training images.\n", "    num_frames=config.num_input_frames + config.num_prediction_frames, # Use 3 frames as input and 1 frame as prediction.\n", "    img_size=config.img_size, # Image size.\n", "    scalers=scalers[0:1] # Use just ir069 scaler.\n", "    ).shuffle()\n", "valid_ds = CloudDataset(\n", "    files=files[2:3], # Use just ir069 validation images.\n", "    num_frames=config.num_input_frames + 3, # Use 3 frames as input and 3 frames as target.\n", "    img_size=config.img_size, # Image size.\n", "    scalers=scalers[0:1]) # Use just ir069 scaler."]}, {"cell_type": "code", "execution_count": 10, "metadata": {"id": "c8j7giH3QzcB", "colab": {"base_uri": "https://localhost:8080/"}, "executionInfo": {"status": "ok", "timestamp": 1696937486056, "user_tz": -120, "elapsed": 523, "user": {"displayName": "Riccardo Spolaor", "userId": "04097970246471970760"}}, "outputId": "9d9f7240-16bc-4a87-d617-9800824b4fd8"}, "outputs": [{"output_type": "stream", "name": "stderr", "text": ["/usr/local/lib/python3.10/dist-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.\n", "  _future_warning(\n", "/usr/local/lib/python3.10/dist-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `StructuralSimilarityIndexMeasure` from `torchmetrics` was deprecated and will be removed in 2.0. Import `StructuralSimilarityIndexMeasure` from `torchmetrics.image` instead.\n", "  _future_warning(\n"]}], "source": ["from src.dataloader import NoisifyDataloader, ValidationDataloader\n", "from src.model import UNet2DTemporalCondition\n", "from src.sampler import ddim_sampler\n", "from src.training import MiniTrainer\n", "\n", "\n", "# Build the DDPM noise train and validation dataloaders.\n", "train_dataloader = NoisifyDataloader(\n", "    train_ds,\n", "    config.batch_size,\n", "    shuffle=True,\n", "    n_frames_to_nosify=config.num_prediction_frames,\n", "    num_workers=config.num_workers)\n", "\n", "valid_dataloader = ValidationDataloader(\n", "    valid_ds,\n", "    config.batch_size,\n", "    n_past_frames=config.num_input_frames,\n", "    shuffle=False,\n", "    num_workers=config.num_workers)\n", "\n", "# Setup the model.\n", "model = UNet2DTemporalCondition(**config.model_params)\n", "\n", "# Setup the sampler.\n", "sampler = ddim_sampler(\n", "    steps=config.sampler_steps,\n", "    n_frames_to_predict=config.num_prediction_frames,\n", "    n_channels=config.num_channels)\n", "\n", "# Get the trainer.\n", "trainer = MiniTrainer(\n", "    train_dataloader,\n", "    valid_dataloader,\n", "    model,\n", "    sampler,\n", "    scalers[0],\n", "    device,\n", "    n_frames_to_predict=config.num_prediction_frames,\n", "    n_auto_regression_steps=3)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 409}, "id": "RGFoNcYpHNVq", "outputId": "2f73b2f1-d1b8-4bbf-8b60-a6b5be5c008b"}, "outputs": [{"output_type": "display_data", "data": {"text/plain": ["<IPython.core.display.HTML object>"], "text/html": ["Tracking run with wandb version 0.15.12"]}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["<IPython.core.display.HTML object>"], "text/html": ["Run data is saved locally in <code>/content/wandb/run-20231010_113126-q7wdynwx</code>"]}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["<IPython.core.display.HTML object>"], "text/html": ["Syncing run <strong><a href='https://wandb.ai/ai-industry/cloud-diffuser-unet-gru-last-output/runs/q7wdynwx' target=\"_blank\">sandy-haze-14</a></strong> to <a href='https://wandb.ai/ai-industry/cloud-diffuser-unet-gru-last-output' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"]}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["<IPython.core.display.HTML object>"], "text/html": [" View project at <a href='https://wandb.ai/ai-industry/cloud-diffuser-unet-gru-last-output' target=\"_blank\">https://wandb.ai/ai-industry/cloud-diffuser-unet-gru-last-output</a>"]}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["<IPython.core.display.HTML object>"], "text/html": [" View run at <a href='https://wandb.ai/ai-industry/cloud-diffuser-unet-gru-last-output/runs/q7wdynwx' target=\"_blank\">https://wandb.ai/ai-industry/cloud-diffuser-unet-gru-last-output/runs/q7wdynwx</a>"]}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["<IPython.core.display.HTML object>"], "text/html": ["\n", "<style>\n", "    /* Turns off some styling */\n", "    progress {\n", "        /* gets rid of default border in Firefox and Opera. */\n", "        border: none;\n", "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n", "        background-size: auto;\n", "    }\n", "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n", "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n", "    }\n", "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n", "        background: #F44336;\n", "    }\n", "</style>\n"]}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["<IPython.core.display.HTML object>"], "text/html": ["\n", "    <div>\n", "      <progress value='0' class='' max='101' style='width:300px; height:20px; vertical-align: middle;'></progress>\n", "      0.00% [0/101 00:00&lt;?]\n", "    </div>\n", "    "]}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["<IPython.core.display.HTML object>"], "text/html": ["\n", "<style>\n", "    /* Turns off some styling */\n", "    progress {\n", "        /* gets rid of default border in Firefox and Opera. */\n", "        border: none;\n", "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n", "        background-size: auto;\n", "    }\n", "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n", "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n", "    }\n", "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n", "        background: #F44336;\n", "    }\n", "</style>\n"]}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["<IPython.core.display.HTML object>"], "text/html": ["\n", "    <div>\n", "      <progress value='19' class='' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n", "      100.00% [19/19 00:07&lt;00:00 train epoch=0, MSE=0.989]\n", "    </div>\n", "    "]}, "metadata": {}}, {"output_type": "stream", "name": "stderr", "text": ["/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([128, 3, 64, 64])) that is different to the input size (torch.Size([128, 1, 64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n", "  return F.mse_loss(input, target, reduction=self.reduction)\n", "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([96, 3, 64, 64])) that is different to the input size (torch.Size([96, 1, 64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n", "  return F.mse_loss(input, target, reduction=self.reduction)\n"]}, {"output_type": "display_data", "data": {"text/plain": ["<IPython.core.display.HTML object>"], "text/html": ["\n", "<style>\n", "    /* Turns off some styling */\n", "    progress {\n", "        /* gets rid of default border in Firefox and Opera. */\n", "        border: none;\n", "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n", "        background-size: auto;\n", "    }\n", "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n", "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n", "    }\n", "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n", "        background: #F44336;\n", "    }\n", "</style>\n"]}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["<IPython.core.display.HTML object>"], "text/html": ["\n", "    <div>\n", "      <progress value='0' class='' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n", "      0.00% [0/3 00:00&lt;?]\n", "    </div>\n", "    "]}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["<IPython.core.display.HTML object>"], "text/html": ["\n", "<style>\n", "    /* Turns off some styling */\n", "    progress {\n", "        /* gets rid of default border in Firefox and Opera. */\n", "        border: none;\n", "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n", "        background-size: auto;\n", "    }\n", "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n", "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n", "    }\n", "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n", "        background: #F44336;\n", "    }\n", "</style>\n"]}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["<IPython.core.display.HTML object>"], "text/html": []}, "metadata": {}}, {"output_type": "stream", "name": "stdout", "text": ["torch.Size([64, 3, 64, 64])\n"]}, {"output_type": "stream", "name": "stderr", "text": ["Traceback (most recent call last):\n", "  File \"<ipython-input-11-84f94028a0f0>\", line 9, in <cell line: 4>\n", "    histories = trainer.fit(config)\n", "  File \"/content/src/training.py\", line 313, in fit\n", "    self.one_epoch_validation(\n", "  File \"/content/src/training.py\", line 209, in one_epoch_validation\n", "    prediction_frames = prediction_frames.reshape(\n", "RuntimeError: shape '[64, 1, 1, 64, 64]' is invalid for input of size 786432\n"]}], "source": ["# trainer = MiniTrainer(train_dataloader, valid_dataloader, model, sampler, device)\n", "\n", "# Train the model.\n", "with wandb.init(\n", "    project='cloud-diffuser-unet-gru-last-output',\n", "    entity='ai-industry',\n", "    config=config,\n", "    tags=['ddpm', config.model_name]):\n", "    histories = trainer.fit(config)"]}, {"cell_type": "code", "source": ["from src.visualization import plot_metrics\n", "\n", "plot_metrics(\n", "    *histories[:2],\n", "    PSNR=histories[2],\n", "    SSIM=histories[3],\n", "    mCSI=histories[4])"], "metadata": {"id": "bV8WOSQ6CSjG", "executionInfo": {"status": "aborted", "timestamp": 1696937170481, "user_tz": -120, "elapsed": 36, "user": {"displayName": "Riccardo Spolaor", "userId": "04097970246471970760"}}}, "execution_count": null, "outputs": []}], "metadata": {"accelerator": "GPU", "colab": {"gpuType": "T4", "machine_shape": "hm", "provenance": []}, "kernelspec": {"display_name": "Python 3", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.10.0"}}, "nbformat": 4, "nbformat_minor": 0}